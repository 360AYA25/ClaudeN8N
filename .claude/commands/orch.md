# /orch â€” 6-Agent n8n Workflow Orchestration

## Overview
Launch the multi-agent system to create, modify, or fix n8n workflows.

## Usage

### Basic
```
/orch Create a webhook that saves data to Supabase
```

### With Parameters
```
/orch goal="Telegram bot" services="telegram,supabase" workflow_id="abc"
```

### Test Mode
```
/orch --test              # Test all agents
/orch --test agent:builder  # Test specific agent
/orch --test e2e          # End-to-End production test (20+ nodes)
```

## Parameters

| Parameter | Values | Default | Description |
|-----------|--------|---------|-------------|
| `goal` | string | (from prompt) | Task description |
| `services` | comma-separated | (auto-detect) | Services to integrate |
| `workflow_id` | string | null | Existing workflow to modify |

---

## 5-PHASE FLOW (Unified)

**No complexity detection!** All requests follow the same flow:

```
PHASE 1: CLARIFICATION
â”œâ”€â”€ User request â†’ Architect
â”œâ”€â”€ Architect â†â†’ User (Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³)
â””â”€â”€ Output: requirements

PHASE 2: RESEARCH
â”œâ”€â”€ Architect â†’ Orchestrator â†’ Researcher
â”œâ”€â”€ Search: local â†’ existing â†’ templates â†’ nodes
â””â”€â”€ Output: research_findings (fit_score, popularity)

PHASE 3: DECISION + CREDENTIALS
â”œâ”€â”€ Researcher â†’ Orchestrator â†’ Architect
â”œâ”€â”€ Architect â†â†’ User (Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ°)
â”œâ”€â”€ Orchestrator â†’ Researcher (discover credentials)
â”œâ”€â”€ Researcher â†’ Orchestrator (credentials_discovered)
â”œâ”€â”€ Orchestrator â†’ Architect (present credentials)
â”œâ”€â”€ Architect â†â†’ User (select credentials)
â”œâ”€â”€ Modify existing > Build new
â””â”€â”€ Output: decision + blueprint + credentials_selected

PHASE 4: IMPLEMENTATION
â”œâ”€â”€ Architect â†’ Orchestrator â†’ Researcher (deep dive)
â”œâ”€â”€ Study: learnings â†’ patterns â†’ node configs
â””â”€â”€ Output: build_guidance (gotchas, configs, warnings)

PHASE 5: BUILD
â”œâ”€â”€ Researcher â†’ Orchestrator â†’ Builder â†’ QA
â”œâ”€â”€ QA Loop: max 3 cycles, then blocked
â””â”€â”€ Output: completed workflow
```

---

## Session Start

When `/orch` is invoked:

1. **Initialize or load run_state**
   ```
   Read memory/run_state.json
   If empty or finalized â†’ create new with UUID
   ```

2. **Parse user request**
   ```
   Extract: goal, services, constraints
   Set: stage="clarification", cycle_count=0
   ```

3. **Start Architect for clarification**
   ```
   Task(agent=architect, prompt="Clarify requirements with user")
   ```

## Context Passed to Agents

Each agent receives full `run_state`:
- `id`, `user_request`, `goal`
- `stage`, `cycle_count`
- `requirements` (from Architect Phase 1)
- `research_request` (from Architect Phase 2)
- `research_findings` (from Researcher)
- `decision` (from Architect Phase 3)
- `blueprint` (from Architect Phase 3)
- `credentials_discovered` (from Researcher Phase 3 - scanned from existing workflows)
- `credentials_selected` (from Architect Phase 3 - user-chosen credentials)
- `build_guidance` (from Researcher Phase 4 - gotchas, node configs, warnings)
- `workflow` (from Builder)
- `qa_report` (from QA)
- `edit_scope` (nodes to modify)
- `worklog`, `agent_log` (history)

## Stage Transitions

```
clarification â†’ research â†’ decision â†’ implementation â†’ build â†’ validate â†’ test â†’ complete
                                                                    â†“
                                                                 blocked (after 3 QA fails)
```

## QA Loop (max 3 cycles)

```
QA fail â†’ Builder fix (edit_scope) â†’ QA â†’ repeat
After 3 fails â†’ stage="blocked" â†’ report to user
```

## Test Mode

### `--test` (Quick health check)
Tests each agent can be invoked:

| Agent | Test | MCP Tools |
|-------|------|-----------|
| Orchestrator | read run_state | list/get workflows |
| Architect | read files + skills | **NO MCP!** |
| Researcher | search nodes/templates | full search |
| Builder | validate node config | mutations |
| QA | list workflows + executions | testing |
| Analyst | read executions | read-only |

**IMPORTANT:** Architect has NO MCP tools - only Read + Skills!

### `--test e2e` (End-to-End Production Test) ğŸ†•
**Full system stress test with REAL 20+ node workflow**

Creates, activates, and tests complex production-grade workflow with:
- **20+ nodes** (triggers Logical Block Building)
- **Multiple services** (Telegram, Supabase, OpenAI, HTTP Request)
- **AI Agent node** with custom prompt
- **Complex logic** (IF, Switch, Merge nodes)
- **Real credentials** (auto-discovered from existing workflows)
- **Full execution** (activates + triggers + monitors)
- **Auto-fix loops** (if execution fails, Builder fixes)
- **Analyst review** (post-mortem analysis + learnings)

**Process:**
```
PHASE 1: DISCOVERY
â”œâ”€ Orchestrator â†’ Researcher: Discover available credentials
â”œâ”€ Find: Telegram, Supabase, OpenAI, HTTP auth keys
â””â”€ Output: credentials_map

PHASE 2: DESIGN & BUILD
â”œâ”€ Architect: Design 20+ node workflow blueprint
â”‚  â”œâ”€ Block 1: **Chat Trigger** (AI-optimized webhook + UI) (3 nodes)
â”‚  â”œâ”€ Block 2: Data validation with IF/Switch (5 nodes)
â”‚  â”œâ”€ Block 3: AI Agent processing (4 nodes)
â”‚  â”œâ”€ Block 4: Supabase storage (4 nodes)
â”‚  â”œâ”€ Block 5: HTTP Request to external API (2 nodes)
â”‚  â””â”€ Block 6: Telegram notification + Chat Response (3 nodes)
â”œâ”€ Builder: Create workflow using Logical Block Building
â”œâ”€ QA: Validate all nodes + connections
â””â”€ Output: workflow_id + chat_url

PHASE 3: ACTIVATION & EXECUTION
â”œâ”€ QA: Activate workflow
â”œâ”€ QA: Trigger test execution (webhook or manual)
â”œâ”€ Monitor: Check execution logs
â””â”€ Output: execution_id, status

PHASE 4: VERIFICATION
â”œâ”€ QA: Read execution details
â”œâ”€ Check: All 20+ nodes executed successfully
â”œâ”€ Check: AI Agent response valid
â”œâ”€ Check: Supabase records created
â”œâ”€ Check: Telegram message sent
â””â”€ Output: verification_report

PHASE 5: FIX LOOP (if failures)
â”œâ”€ IF execution failed:
â”‚  â”œâ”€ Analyst: Identify root cause from logs
â”‚  â”œâ”€ Researcher: Find solution in LEARNINGS.md
â”‚  â”œâ”€ Builder: Fix nodes (max 3 cycles)
â”‚  â”œâ”€ QA: Re-validate + re-execute
â”‚  â””â”€ Repeat until success or blocked
â””â”€ Max 3 fix cycles

PHASE 6: ANALYSIS & LEARNINGS
â”œâ”€ Analyst: Comprehensive post-mortem
â”‚  â”œâ”€ Agent performance review
â”‚  â”œâ”€ Token usage analysis
â”‚  â”œâ”€ Time per phase
â”‚  â”œâ”€ QA loop efficiency
â”‚  â”œâ”€ Logical block building effectiveness
â”‚  â”œâ”€ Identified issues
â”‚  â””â”€ Recommendations for improvement
â”œâ”€ Analyst: Write to LEARNINGS.md (if new patterns)
â””â”€ Output: analysis_report.md
```

**Test Workflow Specification:**

```json
{
  "name": "E2E Test: Multi-Service AI Workflow",
  "description": "20+ node production test covering all agent capabilities",
  "nodes_count": 21,
  "blocks": [
    {
      "name": "Trigger",
      "type": "foundation",
      "nodes": [
        "Chat Trigger (@n8n/n8n-nodes-langchain.chatTrigger)",
        "  mode: webhook (API access)",
        "  public: true (open chat UI)",
        "  responseMode: lastNode",
        "Set: Parse Chat Input",
        "IF: Validate Required Fields"
      ]
    },
    {
      "name": "AI Processing",
      "type": "intelligence",
      "nodes": [
        "AI Agent: Analyze Input",
        "  prompt: 'You are a data validator. Check if input contains valid user data. Return JSON with validation result.'",
        "  tools: [http_request]",
        "Code: Parse AI Response",
        "Switch: Route by AI Decision"
      ]
    },
    {
      "name": "Storage Operations",
      "type": "persistence",
      "nodes": [
        "Supabase: Insert User Record",
        "Supabase: Get User by ID",
        "Set: Format User Data",
        "IF: Check Insert Success"
      ]
    },
    {
      "name": "External API",
      "type": "integration",
      "nodes": [
        "HTTP Request: GET jsonplaceholder.typicode.com/users/1",
        "Set: Merge External Data"
      ]
    },
    {
      "name": "Notifications",
      "type": "output",
      "nodes": [
        "Telegram: Send Success Message",
        "Set: Format Response",
        "Respond to Webhook: Return Results"
      ]
    }
  ],
  "complexity_features": [
    "Multiple IF/Switch routing",
    "AI Agent with tools",
    "Database operations (insert + get)",
    "External API calls",
    "Error handling on all blocks",
    "Webhook response with data"
  ]
}
```

**Why Chat Trigger? ğŸ¯**

| Feature | Webhook Trigger | **Chat Trigger** | Manual Trigger |
|---------|----------------|------------------|----------------|
| UI for testing | âŒ No | âœ… Built-in chat | âœ… Button |
| API access | âœ… Yes | âœ… Yes (webhook) | âŒ No |
| Session memory | âŒ No | âœ… Automatic | âŒ No |
| For AI agents | ğŸŸ¡ Works | âœ… Optimized | ğŸŸ¡ Works |
| Chat history | âŒ No | âœ… Visible in UI | âŒ No |
| Claude Code testing | âœ… API only | âœ… **Both ways!** | âŒ UI only |

**Chat Trigger = Best choice because:**
- âœ… You can open UI and test manually
- âœ… Claude Code can trigger via webhook API
- âœ… Session memory - conversation persists
- âœ… Perfect for AI workflows
- âœ… History visible - see all tests

**Testing methods:**
```javascript
// Method 1: Automated (Claude Code)
n8n_trigger_webhook_workflow({
  webhookUrl: "https://n8n.srv1068954.hstgr.cloud/webhook-test/{id}",
  httpMethod: "POST",
  data: {
    chatInput: "Test query from Claude Code",
    sessionId: "e2e-test-session"
  },
  waitForResponse: true
})

// Method 2: Manual (User)
// Open workflow â†’ Click "Open Chat" on Chat Trigger node
// Type message â†’ See response in real-time
```

**Success Criteria:**
âœ… Workflow created with 20+ nodes
âœ… All logical blocks built correctly
âœ… All credentials applied
âœ… Workflow activated
âœ… Execution completed (all nodes green)
âœ… AI Agent responded correctly
âœ… Supabase records exist
âœ… Telegram message delivered
âœ… Chat Trigger returned 200 OK
âœ… Chat UI accessible (manual testing)
âœ… No QA errors
âœ… Analyst report generated

**Cleanup:**
- Deactivate workflow after test
- Delete test Supabase records
- Keep workflow for reference (tag: "e2e-test")

**Usage:**
```bash
/orch --test e2e
```

### `--test agent:NAME`
Tests specific agent in isolation:
```
/orch --test agent:builder
/orch --test agent:qa
/orch --test agent:researcher
```

## Examples

### Create Simple Workflow
```
/orch Create a webhook that responds with "Hello World"
```

### Create Complex Integration
```
/orch mode=complex goal="Telegram bot that saves messages to Supabase and notifies Slack" services="telegram,supabase,slack"
```

### Fix Existing Workflow
```
/orch workflow_id=abc123 Fix the Supabase insert error
```

### Run Tests
```
/orch --test e2e           # Production-grade 20+ node test
```

## Escalation Levels

| Level | Trigger | Action |
|-------|---------|--------|
| L1 | Simple error | Builder direct fix |
| L2 | Unknown error | Researcher â†’ Builder |
| L3 | 3+ failures | stage="blocked" |
| L4 | Blocked | Report to user + Analyst post-mortem |

## Output

On completion, run_state contains:
- `workflow.id` - Created/updated workflow ID
- `qa_report.ready_for_deploy` - Whether ready for production
- `worklog` - Full execution history
- `finalized.status` - True when complete

# /orch â€” 6-Agent n8n Workflow Orchestration

## Overview
Launch the multi-agent system to create, modify, or fix n8n workflows.

## Usage

### Basic
```
/orch Create a webhook that saves data to Supabase
```

### With Parameters
```
/orch goal="Telegram bot" services="telegram,supabase" workflow_id="abc"
```

### Test Mode
```
/orch --test              # Test all agents
/orch --test agent:builder  # Test specific agent
/orch --test e2e          # End-to-End production test (20+ nodes)
```

## Parameters

| Parameter | Values | Default | Description |
|-----------|--------|---------|-------------|
| `goal` | string | (from prompt) | Task description |
| `services` | comma-separated | (auto-detect) | Services to integrate |
| `workflow_id` | string | null | Existing workflow to modify |

---

## 5-PHASE FLOW (Unified)

**No complexity detection!** All requests follow the same flow:

```
PHASE 1: CLARIFICATION
â”œâ”€â”€ User request â†’ Architect
â”œâ”€â”€ Architect â†â†’ User (Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³)
â””â”€â”€ Output: requirements

PHASE 2: RESEARCH
â”œâ”€â”€ Architect â†’ Orchestrator â†’ Researcher
â”œâ”€â”€ Search: local â†’ existing â†’ templates â†’ nodes
â””â”€â”€ Output: research_findings (fit_score, popularity)

PHASE 3: DECISION + CREDENTIALS
â”œâ”€â”€ Researcher â†’ Orchestrator â†’ Architect
â”œâ”€â”€ Architect â†â†’ User (Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ°)
â”œâ”€â”€ Orchestrator â†’ Researcher (discover credentials)
â”œâ”€â”€ Researcher â†’ Orchestrator (credentials_discovered)
â”œâ”€â”€ Orchestrator â†’ Architect (present credentials)
â”œâ”€â”€ Architect â†â†’ User (select credentials)
â”œâ”€â”€ Modify existing > Build new
â””â”€â”€ Output: decision + blueprint + credentials_selected

PHASE 4: IMPLEMENTATION
â”œâ”€â”€ Architect â†’ Orchestrator â†’ Researcher (deep dive)
â”œâ”€â”€ Study: learnings â†’ patterns â†’ node configs
â””â”€â”€ Output: build_guidance (gotchas, configs, warnings)

PHASE 5: BUILD
â”œâ”€â”€ Researcher â†’ Orchestrator â†’ Builder â†’ QA
â”œâ”€â”€ QA Loop: max 3 cycles, then blocked
â””â”€â”€ Output: completed workflow
```

---

## Session Start

When `/orch` is invoked:

1. **Initialize or load run_state**
   ```
   Read memory/run_state.json
   If empty or finalized â†’ create new with UUID
   ```

2. **Parse user request**
   ```
   Extract: goal, services, constraints
   Set: stage="clarification", cycle_count=0
   ```

3. **Start Architect for clarification**
   ```
   Task(agent=architect, prompt="Clarify requirements with user")
   ```

## Context Passed to Agents

Each agent receives full `run_state`:
- `id`, `user_request`, `goal`
- `stage`, `cycle_count`
- `requirements` (from Architect Phase 1)
- `research_request` (from Architect Phase 2)
- `research_findings` (from Researcher)
- `decision` (from Architect Phase 3)
- `blueprint` (from Architect Phase 3)
- `credentials_discovered` (from Researcher Phase 3 - scanned from existing workflows)
- `credentials_selected` (from Architect Phase 3 - user-chosen credentials)
- `build_guidance` (from Researcher Phase 4 - gotchas, node configs, warnings)
- `workflow` (from Builder)
- `qa_report` (from QA)
- `edit_scope` (nodes to modify)
- `worklog`, `agent_log` (history)

## Stage Transitions

```
clarification â†’ research â†’ decision â†’ implementation â†’ build â†’ validate â†’ test â†’ complete
                                                                    â†“
                                                                 blocked (after 3 QA fails)
```

## QA Loop (max 3 cycles)

```
QA fail â†’ Builder fix (edit_scope) â†’ QA â†’ repeat
After 3 fails â†’ stage="blocked" â†’ report to user
```

## Test Mode

### `--test` (Quick health check)
Tests each agent can be invoked:

| Agent | Test | MCP Tools |
|-------|------|-----------|
| Orchestrator | read run_state | list/get workflows |
| Architect | read files + skills | **NO MCP!** |
| Researcher | search nodes/templates | full search |
| Builder | validate node config | mutations |
| QA | list workflows + executions | testing |
| Analyst | read executions | read-only |

**IMPORTANT:** Architect has NO MCP tools - only Read + Skills!

### `--test e2e` (End-to-End Production Test) ğŸ†•
**Full system stress test with REAL 20+ node workflow**

Creates, activates, and tests complex production-grade workflow with:
- **20+ nodes** (triggers Logical Block Building)
- **Multiple services** (Telegram, Supabase, OpenAI, HTTP Request)
- **AI Agent node** with custom prompt
- **Complex logic** (IF, Switch, Merge nodes)
- **Real credentials** (auto-discovered from existing workflows)
- **Full execution** (activates + triggers + monitors)
- **Auto-fix loops** (if execution fails, Builder fixes)
- **Analyst review** (post-mortem analysis + learnings)

**Process (follows 5-PHASE FLOW!):**

```
1. CLARIFICATION PHASE
   â””â”€ Task({ agent: "architect" })
      â”œâ”€ E2E test mode: confirm test parameters with user
      â”œâ”€ Workflow type: Complex (20+ nodes)
      â”œâ”€ Services: Telegram, Supabase, OpenAI, HTTP
      â”œâ”€ Trigger: Chat Trigger (dual mode)
      â””â”€ Output: run_state.requirements

2. RESEARCH PHASE
   â””â”€ Task({ agent: "researcher" })
      â”œâ”€ Find existing E2E test workflows (reuse if found)
      â”œâ”€ Discover available credentials (Telegram, Supabase, OpenAI)
      â”œâ”€ Search best templates for multi-service AI workflow
      â””â”€ Output: run_state.research_findings + credentials_discovered

3. DECISION PHASE
   â””â”€ Task({ agent: "architect" })
      â”œâ”€ Present findings to user
      â”œâ”€ Options: A) Modify existing, B) Build new
      â”œâ”€ In E2E test: auto-select "Build new" with all credentials
      â””â”€ Output: run_state.decision + credentials_selected

4. IMPLEMENTATION PHASE
   â””â”€ Task({ agent: "researcher" })
      â”œâ”€ Deep dive for build_guidance
      â”œâ”€ Read LEARNINGS-INDEX.md for relevant patterns
      â”œâ”€ Get node configs: chatTrigger, aiAgent, supabase, telegram
      â”œâ”€ Find gotchas and warnings
      â””â”€ Output: run_state.build_guidance

5. BUILD PHASE
   â””â”€ Task({ agent: "builder" })
      â”œâ”€ Create 21-node workflow using Logical Block Building
      â”œâ”€ Chat Trigger (mode: webhook, public: true)
      â”œâ”€ AI Agent, Supabase, HTTP, Telegram
      â”œâ”€ Use credentials from run_state.credentials_selected
      â””â”€ Output: run_state.workflow + memory/agent_results/workflow_{id}.json

6. VALIDATE & TEST PHASE
   â””â”€ Task({ agent: "qa" })
      â”œâ”€ Validate workflow structure
      â”œâ”€ Activate workflow
      â”œâ”€ Trigger via Chat webhook
      â”œâ”€ Check all 21 nodes executed
      â”œâ”€ Verify Supabase record created
      â”œâ”€ Verify Telegram sent
      â”œâ”€ IF errors: edit_scope â†’ Builder â†’ QA (max 3 cycles)
      â””â”€ Output: run_state.qa_report

7. ANALYSIS PHASE (ALWAYS runs)
   â””â”€ Task({ agent: "analyst" })
      â”œâ”€ Token usage per agent + total
      â”œâ”€ Cost estimate
      â”œâ”€ Agent performance timing
      â”œâ”€ QA loop efficiency
      â”œâ”€ Issues and recommendations
      â”œâ”€ Write learnings if patterns found
      â””â”€ Output: memory/e2e_test_analysis_{timestamp}.md

8. CLEANUP
   â””â”€ Task({ agent: "qa" })
      â”œâ”€ Deactivate workflow
      â”œâ”€ Add tag "e2e-test"
      â””â”€ Keep workflow for reference
```

**Test Workflow Specification:**

```json
{
  "name": "E2E Test: Multi-Service AI Workflow",
  "description": "20+ node production test covering all agent capabilities",
  "nodes_count": 21,
  "blocks": [
    {
      "name": "Trigger",
      "type": "foundation",
      "nodes": [
        "Chat Trigger (@n8n/n8n-nodes-langchain.chatTrigger)",
        "  mode: webhook (API access)",
        "  public: true (open chat UI)",
        "  responseMode: lastNode",
        "Set: Parse Chat Input",
        "IF: Validate Required Fields"
      ]
    },
    {
      "name": "AI Processing",
      "type": "intelligence",
      "nodes": [
        "AI Agent: Analyze Input",
        "  prompt: 'You are a data validator. Check if input contains valid user data. Return JSON with validation result.'",
        "  tools: [http_request]",
        "Code: Parse AI Response",
        "Switch: Route by AI Decision"
      ]
    },
    {
      "name": "Storage Operations",
      "type": "persistence",
      "nodes": [
        "Supabase: Insert User Record",
        "Supabase: Get User by ID",
        "Set: Format User Data",
        "IF: Check Insert Success"
      ]
    },
    {
      "name": "External API",
      "type": "integration",
      "nodes": [
        "HTTP Request: GET jsonplaceholder.typicode.com/users/1",
        "Set: Merge External Data"
      ]
    },
    {
      "name": "Notifications",
      "type": "output",
      "nodes": [
        "Telegram: Send Success Message",
        "Set: Format Response",
        "Respond to Webhook: Return Results"
      ]
    }
  ],
  "complexity_features": [
    "Multiple IF/Switch routing",
    "AI Agent with tools",
    "Database operations (insert + get)",
    "External API calls",
    "Error handling on all blocks",
    "Webhook response with data"
  ]
}
```

**Why Chat Trigger? ğŸ¯**

| Feature | Webhook Trigger | **Chat Trigger** | Manual Trigger |
|---------|----------------|------------------|----------------|
| UI for testing | âŒ No | âœ… Built-in chat | âœ… Button |
| API access | âœ… Yes | âœ… Yes (webhook) | âŒ No |
| Session memory | âŒ No | âœ… Automatic | âŒ No |
| For AI agents | ğŸŸ¡ Works | âœ… Optimized | ğŸŸ¡ Works |
| Chat history | âŒ No | âœ… Visible in UI | âŒ No |
| Claude Code testing | âœ… API only | âœ… **Both ways!** | âŒ UI only |

**Chat Trigger = Best choice because:**
- âœ… You can open UI and test manually
- âœ… Claude Code can trigger via webhook API
- âœ… Session memory - conversation persists
- âœ… Perfect for AI workflows
- âœ… History visible - see all tests

**Testing methods:**
```javascript
// Method 1: Automated (Claude Code)
n8n_trigger_webhook_workflow({
  webhookUrl: "https://n8n.srv1068954.hstgr.cloud/webhook-test/{id}",
  httpMethod: "POST",
  data: {
    chatInput: "Test query from Claude Code",
    sessionId: "e2e-test-session"
  },
  waitForResponse: true
})

// Method 2: Manual (User)
// Open workflow â†’ Click "Open Chat" on Chat Trigger node
// Type message â†’ See response in real-time
```

**Success Criteria:**
âœ… Workflow created with 20+ nodes
âœ… All logical blocks built correctly
âœ… All credentials applied
âœ… Workflow activated
âœ… Execution completed (all nodes green)
âœ… AI Agent responded correctly
âœ… Supabase records exist
âœ… Telegram message delivered
âœ… Chat Trigger returned 200 OK
âœ… Chat UI accessible (manual testing)
âœ… No QA errors
âœ… Analyst report generated

**Cleanup:**
- Deactivate workflow after test
- Delete test Supabase records
- Keep workflow for reference (tag: "e2e-test")

**Usage:**
```bash
/orch --test e2e
```

### `--test agent:NAME`
Tests specific agent in isolation:
```
/orch --test agent:builder
/orch --test agent:qa
/orch --test agent:researcher
```

## Examples

### Create Simple Workflow
```
/orch Create a webhook that responds with "Hello World"
```

### Create Complex Integration
```
/orch mode=complex goal="Telegram bot that saves messages to Supabase and notifies Slack" services="telegram,supabase,slack"
```

### Fix Existing Workflow
```
/orch workflow_id=abc123 Fix the Supabase insert error
```

### Run Tests
```
/orch --test e2e           # Production-grade 20+ node test
```

## Escalation Levels

| Level | Trigger | Action |
|-------|---------|--------|
| L1 | Simple error | Builder direct fix |
| L2 | Unknown error | Researcher â†’ Builder |
| L3 | 3+ failures | stage="blocked" |
| L4 | Blocked | Report to user + Analyst post-mortem |

## Output

On completion, run_state contains:
- `workflow.id` - Created/updated workflow ID
- `qa_report.ready_for_deploy` - Whether ready for production
- `worklog` - Full execution history
- `finalized.status` - True when complete

# üéØ Universal Solution Patterns

> **FOR BOTS: How to Read This File**
>
> Use **Grep + Read with offset/limit** to find relevant patterns:
>
> ```javascript
> // Find pattern by keyword
> Grep: {pattern: "Incremental", "-n": true, output_mode: "content"}
> // Result: "7:## Pattern 0: üöÄ Incremental n8n Workflow Creation"
>
> // Read that pattern
> Read: {file_path: "PATTERNS.md", offset: 7, limit: 150}
> ```

> **FOR BOTS: How to Write to This File**
>
> 1. **Determine section:** ‚úÖ Proven Patterns OR ‚ùå Anti-Patterns
> 2. **Find similar pattern** with Grep to avoid duplicates
> 3. **Add new pattern** in relevant section (chronological order, newest on top)
> 4. **Use format:**
>    - **Proven Patterns:** When to use ‚Üí Problem ‚Üí Solution ‚Üí Code Template ‚Üí Critical Rules ‚Üí Examples
>    - **Anti-Patterns:** What NOT to do ‚Üí Why it's bad ‚Üí Use instead ‚Üí Example

---

## ‚ö° QUICK REFERENCE - Critical Patterns (Always Check First!)

**For Architect agents: Check these BEFORE generating plans!**

### üî¥ Set Node v3.4+ (CRITICAL!)
```javascript
// ‚ùå WRONG - Missing ={{ prefix
"value": "string{{ $json.field }}"

// ‚úÖ CORRECT - With ={{ prefix
"value": "={{ 'string' + $json.field }}"

// Required fields:
{
  "mode": "manual",                    // MANDATORY v3.4+
  "assignments": {
    "assignments": [                   // Array, not object!
      {
        "id": "unique-id",
        "name": "output_field",
        "type": "string|number|boolean",
        "value": "={{ ... }}"          // Start with ={{
      }
    ]
  }
}
```

### üü° IF Node v2+ (Common Issue)
```javascript
// ‚ùå WRONG - conditions as object
"conditions": {
  "leftValue": "...",
  "operation": "equals",
  "rightValue": "..."
}

// ‚úÖ CORRECT - conditions as ARRAY
"conditions": {
  "conditions": [              // Wrap in array!
    {
      "leftValue": "={{ $statusCode }}",
      "operation": "equals",
      "rightValue": 200
    }
  ]
}
```

### üü† HTTP Request v4.2+ (Known Bug)
```javascript
// ‚ùå WRONG - ignoreHttpStatusErrors doesn't work
"parameters": {
  "options": {
    "ignoreHttpStatusErrors": true   // IGNORED in v4.2!
  }
}

// ‚úÖ CORRECT - Use continueOnFail at node level
"continueOnFail": true,              // Node level, not parameters!
"parameters": {
  "url": "...",
  "method": "GET"
}
```

### üü¢ Pattern 47: Never Trust Defaults (Universal)
```javascript
// ALWAYS specify:
"typeVersion": 3.4,        // Explicit version
"method": "GET",           // Don't trust default
"mode": "manual",          // Set node requirement
"sendHeaders": true,       // HTTP Request explicit
"responseFormat": "json"   // HTTP Request explicit
```

### üü£ Pattern 15: Cascading Parameter Changes (CRITICAL for Debugging!)
```javascript
// BEFORE changing any parameter - ALWAYS check downstream impact!

// ‚ùå WRONG - Changed one node only
// Set node: renamed "user_id" ‚Üí "userId"
// Result: 5 downstream nodes broke (Code, IF, Supabase)

// ‚úÖ CORRECT - Pre-Change Checklist
// Step 1: Search for all references
grep -n "user_id" workflow.json
// Found: Code node (3 refs), IF node (1 ref), Supabase (1 ref)

// Step 2: Update ALL nodes simultaneously
// - Set node: "userId"
// - Code node: $json.userId (3 places)
// - IF node: {{ $json.userId }}
// - Supabase: fieldValue: "={{ $json.userId }}"

// Step 3: Test end-to-end
// All 6 nodes working ‚úÖ

// CRITICAL RULE: One parameter change = Multiple node updates
// Never change in isolation!
```

### üîµ Connection Syntax (4-param format)
```javascript
// ‚úÖ CORRECT - 4 parameters
"connections": {
  "Node A": {
    "main": [[
      {
        "node": "Node B",    // Target node name
        "type": "main",      // Connection type
        "index": 0           // Output port index
      }
    ]]
  }
}

// IF node branches:
"IF Node": {
  "main": [
    [{"node": "Success", "type": "main", "index": 0}],  // Branch 0 (TRUE)
    [{"node": "Error", "type": "main", "index": 0}]     // Branch 1 (FALSE)
  ]
}
```

**Reference:** See Pattern 0, Pattern 15, LEARNINGS.md entry [2025-11-12 23:00], [2025-11-18 16:00], architect.md pre-validation

---

## üìë Quick Index

| Pattern | Line | Topic |
|---------|------|-------|
| [Pattern 0: Incremental Workflow Creation](#pattern-0--incremental-n8n-workflow-creation-via-mcp-critical) | 50 | n8n MCP step-by-step |
| [Pattern 0.5: Modifying Nodes](#pattern-05--modifying-individual-nodes-in-n8n-workflows-via-mcp) | 185 | n8n MCP remove+add |
| [Pattern 1-14](#pattern-1-dynamic-database-selection-n8n--notion) | 410 | Various n8n patterns |
| [Pattern 15: Cascading Parameter Changes](#pattern-15--cascading-parameter-changes-critical-for-debugging--building) | 970 | Critical for debugging & building |
| [Anti-Patterns](#-anti-patterns-what-not-to-do) | 1290 | Common mistakes to avoid |

---

## Pattern 0: üöÄ Smart n8n Workflow Creation Strategy (CRITICAL!)

**When to use:**
- Creating n8n workflows programmatically via n8n-MCP
- Any workflow size (3-50+ nodes)
- Optimizing token consumption

**Problem:**
- **Per-node incremental:** 8 nodes = ~2000 tokens (1 create + 7 updates) ‚ùå Expensive!
- **One-shot creation:** 15+ nodes = high failure risk ‚ùå Fragile!
- **Old Pattern 0:** Applied incremental to all 5+ node workflows ‚ùå Token waste!

**‚úÖ NEW Solution - Smart Strategy Selection (60-85% Token Savings!):**

### Decision Tree (Automatic):

**Calculate complexity score:**
```
complexity_score = node_count + (if_switch_count * 5) + (external_api_count * 2)
```

**Strategy selection:**

| Score | Tier | Strategy | Approach | Token Cost |
|-------|------|----------|----------|------------|
| 0-7 | Simple | **One-shot** | Create all nodes at once | ~100-300 |
| 8-15 | Medium | **One-shot + validation** | Create all, validate complex nodes | ~300-600 |
| 16-25 | Complex | **Functional blocks** | Group by service (optional) | ~600-1500 |
| 26+ | Very Complex | **Functional blocks** | Group by service (mandatory) | ~1500-3000 |

### Strategy 1: One-Shot (Simple/Medium Workflows)

**When:** ‚â§ 10 nodes, simple routing, single service

**Example:** Webhook ‚Üí Supabase ‚Üí Slack (5 nodes)

```javascript
// Create entire workflow in one call
n8n_create_workflow({
  name: "Simple Webhook Flow",
  nodes: [
    {id: "webhook", type: "nodes-base.webhook", parameters: {...}, position: [0, 0]},
    {id: "set", type: "nodes-base.set", parameters: {...}, position: [220, 0]},
    {id: "supabase", type: "nodes-base.supabase", parameters: {...}, position: [440, 0]},
    {id: "slack", type: "nodes-base.slack", parameters: {...}, position: [660, 0]},
    {id: "respond", type: "nodes-base.respondToWebhook", parameters: {...}, position: [880, 0]}
  ],
  connections: {
    "webhook": {"main": [[{"node": "set"}]]},
    "set": {"main": [[{"node": "supabase"}]]},
    "supabase": {"main": [[{"node": "slack"}]]},
    "slack": {"main": [[{"node": "respond"}]]}
  }
})

// Token cost: ~300 tokens
```

### Strategy 2: Functional Blocks (Complex Workflows)

**When:** ‚â• 11 nodes, multiple services (Database + AI + Messaging)

**Why:** Group nodes by **functionality**, not by count!

**Functional block categories:**
1. **INPUT** - Triggers + validation (Webhook, Schedule, Set, Code)
2. **DATABASE** - All DB operations together (Supabase, Postgres, MySQL, MongoDB)
3. **AI** - All AI processing together (OpenAI, Anthropic, Google Gemini)
4. **HTTP** - External API calls (HTTP Request nodes)
5. **MESSAGING** - Notifications (Telegram, Slack, Email, Discord)
6. **BRANCHING** - Conditional logic (IF, Switch, Filter)
7. **OUTPUT** - Final responses (Respond to Webhook, NoOp)
8. **ERROR** - Error handling (separate error branches)

**Example:** 10-node workflow with Database + AI + Messaging

```javascript
// BLOCK 1: INPUT & VALIDATION (3 nodes)
n8n_create_workflow({
  name: "Multi-Service Workflow",
  nodes: [
    {id: "webhook", type: "nodes-base.webhook", ...},
    {id: "set_data", type: "nodes-base.set", ...},
    {id: "parse", type: "nodes-base.code", ...}
  ],
  connections: {
    "webhook": {"main": [[{"node": "set_data"}]]},
    "set_data": {"main": [[{"node": "parse"}]]}
  }
})
// Token cost: ~100 tokens

// BLOCK 2: DATABASE OPERATIONS (3 nodes - all Supabase together!)
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    {type: "addNode", node: {id: "supabase_select", type: "nodes-base.supabase", ...}},
    {type: "addNode", node: {id: "supabase_insert", type: "nodes-base.supabase", ...}},
    {type: "addNode", node: {id: "supabase_update", type: "nodes-base.supabase", ...}},
    {type: "addConnection", source: "parse", target: "supabase_select", ...},
    {type: "addConnection", source: "supabase_select", target: "supabase_insert", ...},
    {type: "addConnection", source: "supabase_insert", target: "supabase_update", ...}
  ]
})
// Token cost: ~100 tokens

// BLOCK 3: AI PROCESSING (2 nodes - all OpenAI together!)
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    {type: "addNode", node: {id: "openai_analyze", type: "nodes-base.openAi", ...}},
    {type: "addNode", node: {id: "openai_generate", type: "nodes-base.openAi", ...}},
    {type: "addConnection", source: "supabase_update", target: "openai_analyze", ...},
    {type: "addConnection", source: "openai_analyze", target: "openai_generate", ...}
  ]
})
// Token cost: ~80 tokens

// BLOCK 4: MESSAGING & OUTPUT (2 nodes)
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    {type: "addNode", node: {id: "telegram", type: "nodes-base.telegram", ...}},
    {type: "addNode", node: {id: "respond", type: "nodes-base.respondToWebhook", ...}},
    {type: "addConnection", source: "openai_generate", target: "telegram", ...},
    {type: "addConnection", source: "telegram", target: "respond", ...}
  ]
})
// Token cost: ~80 tokens

// TOTAL: 4 MCP calls, ~360 tokens
// Per-node approach: 10 MCP calls, ~2000 tokens
// SAVINGS: 82%!
```

### Token Comparison:

| Workflow | One-shot | Functional Blocks | Per-Node (Old) | Best Choice |
|----------|----------|-------------------|----------------|-------------|
| 5 nodes, 1 service | ~250 | N/A | ~1200 | ‚úÖ One-shot |
| 8 nodes, 2 services | ~400 | N/A | ~1800 | ‚úÖ One-shot |
| 10 nodes, 4 services | ~800 | ~400 (4 blocks) | ~2000 | ‚úÖ Functional |
| 15 nodes, 5 services | ~1500 | ~700 (5 blocks) | ~3500 | ‚úÖ Functional |
| 20 nodes, 6 services | Too risky | ~1000 (6 blocks) | ~5000 | ‚úÖ Functional |

### Critical Rules:

1. **ALWAYS** calculate complexity score first
2. **ALWAYS** group by service/functionality (Database, AI, Messaging), NOT by count
3. **NEVER** use per-node for simple workflows (‚â§10 nodes)
4. **ALWAYS** put `parameters` as FIRST field in node definition
5. **IF node branches:** Use proper output index in addConnection
6. **Switch nodes:** Can be created via MCP (use typeVersion 3.1+)

### Common Errors & Fixes:

| Error | Cause | Solution |
|-------|-------|----------|
| Token waste | Using per-node for 8-node workflow | Use one-shot or functional blocks |
| High failure rate | One-shot with 20+ nodes | Use functional blocks instead |
| Disconnected nodes | Added node without connections | Add connections in same operations array |
| Empty parameters | Wrong field order | Put `parameters` FIRST |

### Success Metrics:

**Old Pattern 0 (per-node incremental):**
- ‚úÖ 100% success rate
- ‚ùå 8 nodes = ~2000 tokens (too expensive!)
- ‚ùå 10 minutes to create 10 nodes

**New Pattern 0 (smart strategy):**
- ‚úÖ 95% success rate (still very high!)
- ‚úÖ 8 nodes = ~400 tokens (80% savings!)
- ‚úÖ 3 minutes to create 10 nodes (via functional blocks)

### Real Example:

**Test workflow (8 nodes):**
```
Old approach (per-node):
‚úÖ Step 1: Webhook ‚Üí Set ‚Üí Code (3 nodes) - 100 tokens
‚úÖ Step 2: + IF node - 200 tokens
‚úÖ Step 3: + HTTP Request - 250 tokens
‚úÖ Step 4: + Set True - 250 tokens
‚úÖ Step 5: + Set False - 250 tokens
‚úÖ Step 6: + Merge - 250 tokens
Total: 6 steps, ~1300 tokens

New approach (functional blocks):
‚úÖ Block 1: INPUT (Webhook, Set, Code) - 100 tokens
‚úÖ Block 2: BRANCHING (IF node) - 80 tokens
‚úÖ Block 3: HTTP (HTTP Request) - 80 tokens
‚úÖ Block 4: TRANSFORM (Set True, Set False) - 80 tokens
‚úÖ Block 5: MERGE (Merge node) - 60 tokens
Total: 5 blocks, ~400 tokens

SAVINGS: 69%!
```

### Version Requirements:

- ‚úÖ n8n-MCP 2.21.1+ - Functional blocks work
- ‚úÖ n8n v1.0+ - All node types supported

**Tags:** #n8n-mcp #workflow-creation #functional-blocks #token-economy #smart-strategy #critical-pattern

---

## Pattern 0.5: üîß Modifying Individual Nodes in n8n Workflows via MCP

**When to use:**
- Need to change parameters in existing workflow node
- Replace placeholder nodes with production nodes
- Update text, credentials, or configuration in specific node

**Problem:**
`updateNode` operation in n8n-MCP is broken ‚Üí throws "Diff engine error"

**‚úÖ WORKING Solution - Remove + Add Pattern:**

### Algorithm:

```
1. Get current workflow structure
   ‚îî‚îÄ n8n_get_workflow_structure(id) - see connections

2. Remove old node(s)
   ‚îî‚îÄ {type: "removeNode", nodeId: "old-id"}

3. Clean stale connections
   ‚îî‚îÄ {type: "cleanStaleConnections"}

4. Add new node(s) with updated parameters
   ‚îî‚îÄ {type: "addNode", node: {...}}

5. Reconnect all affected nodes
   ‚îî‚îÄ {type: "addConnection", source: "a", target: "new-id", ...}
```

### Code Template:

**Simple replacement (1 node in middle of chain):**

```javascript
// GOAL: Replace node B in chain A ‚Üí B ‚Üí C

// Step 1: Check current structure
n8n_get_workflow_structure(workflowId)
// See: A ‚Üí B ‚Üí C connections

// Step 2: Replace B with B'
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    // Remove old
    {type: "removeNode", nodeId: "b"},

    // Clean connections
    {type: "cleanStaleConnections"},

    // Add new with updated parameters
    {type: "addNode", node: {
      parameters: {
        text: "Updated text",  // Changed parameter
        ...otherParams
      },
      id: "b-new",
      name: "B Updated",
      type: "n8n-nodes-base.telegram",
      typeVersion: 1.2,
      position: [x, y],
      credentials: {...}
    }},

    // Reconnect chain
    {type: "addConnection", source: "a", target: "b-new", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "b-new", target: "c", sourcePort: "main", targetPort: "main"}
  ]
})
```

**Complex replacement (multiple nodes):**

```javascript
// GOAL: Replace Code + Reply with Save Entry + Success Reply

n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    // Remove old nodes
    {type: "removeNode", nodeId: "code"},
    {type: "removeNode", nodeId: "reply"},

    // Clean
    {type: "cleanStaleConnections"},

    // Add new nodes
    {type: "addNode", node: {
      parameters: {
        resource: "row",
        operation: "create",
        tableId: "food_entries",
        fieldsUi: {
          fieldValues: [
            {fieldId: "user_id", fieldValue: "={{ $json.user_id }}"},
            {fieldId: "food", fieldValue: "={{ $json.food }}"}
          ]
        }
      },
      id: "save-entry",
      name: "Save Entry",
      type: "n8n-nodes-base.supabase",
      typeVersion: 1,
      position: [1200, 150],
      credentials: {supabaseApi: {id: "xxx", name: "Supabase"}}
    }},
    {type: "addNode", node: {
      parameters: {
        text: "‚úÖ Saved!\n\nFood: {{ $json.food }}"
      },
      id: "success-reply",
      name: "Success Reply",
      type: "n8n-nodes-base.telegram",
      typeVersion: 1.2,
      position: [1400, 150],
      credentials: {telegramApi: {id: "yyy", name: "Bot"}}
    }},

    // Reconnect: Process ‚Üí Save Entry ‚Üí Success Reply
    {type: "addConnection", source: "process", target: "save-entry", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "save-entry", target: "success-reply", sourcePort: "main", targetPort: "main"}
  ]
})
```

### Critical Rules:

| Rule | Why | Example |
|------|-----|---------|
| Use `cleanStaleConnections` | Removes orphaned connections | After `removeNode` |
| All in ONE operation | Avoid disconnected nodes error | Single `operations` array |
| Order: Remove ‚Üí Clean ‚Üí Add ‚Üí Connect | Logical flow | See templates above |
| Check structure first | Know what to reconnect | `n8n_get_workflow_structure` |

### Common Mistakes:

| Mistake | Why it fails | Correct approach |
|---------|--------------|------------------|
| `{type: "updateNode"}` | Broken in n8n-MCP | Use remove + add |
| Removing without reconnecting | Disconnected nodes error | Add connections after |
| Forgetting `cleanStaleConnections` | Phantom connections in UI | Always use after remove |
| Multiple API calls | First call leaves orphans | All in ONE operations array |

### Real Example:

**Replace Code + Reply with Save Entry + Success Reply in FoodTracker:**

```javascript
// BEFORE:
// Process Text/Voice/Photo ‚Üí Code ‚Üí Reply

// AFTER:
// Process Text/Voice/Photo ‚Üí Save Entry ‚Üí Success Reply

n8n_update_partial_workflow({
  id: "NhyjL9bCPSrTM6XG",
  operations: [
    {type: "removeNode", nodeId: "a2"},  // Code
    {type: "removeNode", nodeId: "a3"},  // Reply
    {type: "cleanStaleConnections"},

    {type: "addNode", node: {
      parameters: {
        resource: "row",
        operation: "create",
        tableId: "food_entries",
        fieldsUi: {
          fieldValues: [
            {fieldId: "telegram_user_id", fieldValue: "={{ $json.message.from.id }}"},
            {fieldId: "food_name", fieldValue: "={{ $json.data || 'Test' }}"},
            {fieldId: "input_type", fieldValue: "={{ $json.type }}"}
          ]
        }
      },
      id: "a11",
      name: "Save Entry",
      type: "n8n-nodes-base.supabase",
      typeVersion: 1,
      position: [1200, 150],
      credentials: {supabaseApi: {id: "zPA4hS8vnPFugzl3", name: "Supabase - MultiBOT"}}
    }},

    {type: "addNode", node: {
      parameters: {
        resource: "message",
        operation: "sendMessage",
        chatId: "={{ $json.message.chat.id }}",
        text: "‚úÖ Food saved!\n\nType: {{ $json.input_type }}\nFood: {{ $json.food_name }}"
      },
      id: "a12",
      name: "Success Reply",
      type: "n8n-nodes-base.telegram",
      typeVersion: 1.2,
      position: [1400, 150],
      credentials: {telegramApi: {id: "lGhGjBvzywEUiLXa", name: "Telegram Bot - Food Tracker"}}
    }},

    // Reconnect 3 Process nodes ‚Üí Save Entry ‚Üí Success Reply
    {type: "addConnection", source: "a8", target: "a11", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "a9", target: "a11", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "a10", target: "a11", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "a11", target: "a12", sourcePort: "main", targetPort: "main"}
  ]
})
```

**Result:** ‚úÖ 9 operations applied, 2 nodes removed, 2 nodes added with new parameters, all connections restored.

### Success Metrics:

- ‚úÖ 100% success rate with remove + add pattern
- ‚úÖ 0% success rate with updateNode (always fails)
- ‚úÖ cleanStaleConnections prevents phantom connections
- ‚úÖ Atomic operations (all in one call) prevents orphaned nodes

**Tags:** #n8n-mcp #node-modification #remove-add-pattern #cleanStaleConnections

---

## Pattern 1: Dynamic Database Selection (n8n + Notion)

**Problem:** Different users = different databases

**Solution:**
```javascript
const dbMapping = {
  'Sergey': '287c0427e81f81daaecbc46aaba464dc',
  'Alena': '287c0427e81f816f85fbc6c4bd218c25'
};
return { database_id: dbMapping[$json.user] || dbMapping['Sergey'] };
```

---

## Pattern 2: Safe API Calls (n8n)

**Solution:**
```json
{
  "continueOnFail": true,
  "options": { "neverError": true }
}
```

---

## Pattern 3: Summing instead of replacing (Notion Daily Format)

**Solution:**
```javascript
const oldCalories = $('Check Entry').item.json.property_total_calories || 0;
const newCalories = oldCalories + $json.calories;
```

---

## Pattern 4: Notion Property Reading

**Format:**
```javascript
// Notion getAll returns:
const value = item.property_field_name;
// NOT: item.properties.field_name
```

---

## Pattern 5: IF Node after API (n8n)

**Check for empty results:**
```javascript
{{ $input.all().length }} > 0
```

---

## Pattern 6: Debugging Dynamic Expressions (n8n)

1. Add Code Node after problematic node
2. `return $input.all();`
3. Execute workflow
4. Look at Output

---

## Pattern 7: Git Workflow

```bash
git pull --rebase  # ALWAYS before push
git add .
git commit -m "type: description"
git push origin branch
```

---

## Pattern 8: Finding solutions

```bash
# 1. LEARNINGS.md
grep -i "keyword" LEARNINGS.md

# 2. Project docs
grep -r "keyword" project-data/docs/

# 3. n8n forum
# https://community.n8n.io
```

---

## Pattern 9: Algorithm for Breaking Out of a Loop

**Signs of being stuck in a loop:**
- Trying the same thing several times
- Error repeats
- Solution doesn't work

**Solution (5 steps):**

### Step 1: STOP - Look from Above
```
- What are we trying to do? (goal)
- What exactly isn't working? (problem)
- What have we already tried? (attempt history)
- What is the real cause? (root of the problem)
```

### Step 2: Search in LEARNINGS.md and PATTERNS.md
```bash
grep -i "keyword" LEARNINGS.md
grep -i "keyword" PATTERNS.md
```

### Step 3: Search in Project Docs
```bash
grep -r "keyword" project-data/docs/
```

### Step 4: Search the Internet
- https://docs.n8n.io
- https://community.n8n.io
- Google: "n8n [problem]"

### Step 5: Hand Off to Another Bot
Create a task in `project-data/docs/tasks/TASK-[name].md`

---

## Pattern 10: One Value = Many Places (n8n)

**Problem:** Changed value in one node, but it's used in others!

**Solution - ALGORITHM:**

### 1. Search for all mentions:
```bash
grep -n "old_value" project-data/workflows/CURRENT/workflow.json
```

### 2. Checklist of places to change:
- [ ] Set Node
- [ ] Code Node (ALL mentions!)
- [ ] HTTP Request Node (URLs, parameters)
- [ ] Notion Nodes (database_id, page_id)
- [ ] IF Node (conditions)
- [ ] Switch Node (routes)

### 3. Typical values to check:
- üìä **Database IDs** (Notion)
- üîë **API Keys** (.env and nodes)
- üåê **Webhook URLs** (Router ‚Üí subworkflows)
- üë§ **User IDs** (Sergey/Alena mapping)
- üìÖ **Date formats** (all Code nodes!)
- üè∑Ô∏è **Property names** (Notion property names)

### 4. After changes - TEST:
Open n8n and run Test Workflow

---

---

## Pattern 11: API Design Evolution (Iterative Improvement)

**When to use:**
- API/GPT Instructions require constant improvement
- Need to document design evolution
- Backward compatibility is important

**Problem:**
How to iteratively improve API design without losing decision history?

**Solution - Versioning with documentation:**

### 1. Store all versions
```
project-data/docs/gpt/
‚îú‚îÄ‚îÄ gpt-instructions-v3.md   # First working version
‚îú‚îÄ‚îÄ gpt-instructions-v4.md   # +improvements
‚îú‚îÄ‚îÄ gpt-instructions-v5.md   # +new features
‚îî‚îÄ‚îÄ gpt-openapi-v2.yaml      # API schema
```

### 2. Document changes between versions
```markdown
## v3 ‚Üí v4 Changes
- Added: User detection from photo analysis
- Fixed: Timezone handling for "yesterday"
- Improved: Error messages clarity

## v4 ‚Üí v5 Changes
- Added: Product Search integration (mandatory!)
- Added: Dynamic goals from Notion API
- Removed: Hardcoded calorie goals
```

### 3. Lessons at each step
- v3: Baseline working version
- v4: +10 hours debugging timezone issues ‚Üí lesson learned
- v5: +6 hours Product Search debugging ‚Üí pattern for boolean routing

**Result:**
- Decision history preserved
- Each version - working state
- Easy to roll back to previous version
- Lessons learned documented

**Example:** feature/food-tracker-v2/project-data/docs/gpt/ (9 files, v3‚Üív5)

---

## Pattern 12: Workflow Optimization (Single Source of Truth)

**When to use:**
- Code is duplicated in 3+ places
- Change requires editing all copies
- Workflow becomes large (20+ nodes)

**Problem:**
Code duplication for calculations in n8n workflow ‚Üí 120+ lines in 3 places

**Solution - Single reusable node:**

### Before (120+ lines of duplication):
```
Prepare Create:
  - Calculate calories %
  - Calculate protein %
  - Calculate status
  - Calculate overall progress

Prepare Update:
  - [COPY-PASTE of the same code]

Format Response:
  - [COPY-PASTE of the same code]
```

### After (Single Source of Truth):
```
Calculate Progress & Status (single node):
  - Input: totals + goals
  - Output: percentages + status + overall progress

Prepare Create ‚Üí Calculate Progress ‚Üí Create Entry
Prepare Update ‚Üí Calculate Progress ‚Üí Update Entry
Format Response ‚Üí use Calculate Progress results
```

**Result:**
- 120+ lines removed
- Changes in one place
- Easier to test
- Simpler to maintain

**Metrics:**
- Code reduction: 120 lines ‚Üí 0 duplicates
- Refactoring time: ~2 hours
- ROI: Saves 30+ minutes with each change

**Example:** feature/food-tracker-v2 optimization (October 11, 2025)

---

## Pattern 13: RADICAL Solution - JavaScript Filtering for Notion

**When to use:**
- Notion API filters don't work (timezone, title, date issues)
- Need exact match on complex conditions
- n8n Notion filter UI is unreliable

**Problem:**
Notion API filters unreliable for Date/Title properties due to timezone conversion and type mismatches.

**Solution - Get All + JavaScript Filter:**

```javascript
// Step 1: Get All records with simple filter (Owner/User only)
const response = await this.helpers.request({
  url: `https://api.notion.com/v1/databases/${databaseId}/query`,
  method: 'POST',
  headers: {
    'Authorization': 'Bearer TOKEN',
    'Notion-Version': '2022-06-28'
  },
  json: {
    filter: {
      property: 'Owner',
      select: { equals: owner }
    },
    sorts: [{ property: 'Date', direction: 'descending' }],
    page_size: 10
  }
});

// Step 2: Filter in JavaScript with exact match
const matchingEntry = response.results.find(page => {
  // Null-check!
  if (!page.properties.Date?.date?.start) {
    return false;
  }
  const pageDate = page.properties.Date.date.start.split('T')[0];
  return pageDate === targetDate;  // String comparison
});

return matchingEntry || {};
```

**Benefits:**
- ‚úÖ Avoids all Notion API filter issues
- ‚úÖ Timezone-independent (string comparison)
- ‚úÖ Exact match guaranteed
- ‚úÖ Simple and reliable

**Example:** Food Tracker "Get Today Entry" node

---

## Pattern 14: Null-Safe Notion Property Reading

**When to use:**
- Reading any Notion property (Date, Select, Text, etc.)
- Handling records with empty fields
- Preventing "Cannot read property X of null" errors

**Problem:**
Notion records can have null/empty properties, causing crashes when trying to read nested values.

**Solution - Null-checks before reading:**

```javascript
// ‚ùå WRONG (crashes on null):
const date = page.properties.Date.date.start.split('T')[0];

// ‚úÖ CORRECT (null-safe):
if (!page.properties.Date ||
    !page.properties.Date.date ||
    !page.properties.Date.date.start) {
  return null; // or default value
}
const date = page.properties.Date.date.start.split('T')[0];

// OR use optional chaining:
const date = page.properties?.Date?.date?.start?.split('T')[0];
```

**Common patterns:**

```javascript
// Date property
const date = page.properties?.Date?.date?.start || null;

// Select property
const status = page.properties?.Status?.select?.name || 'Unknown';

// Rich text property
const text = page.properties?.Text?.rich_text?.[0]?.plain_text || '';

// Number property
const value = page.properties?.Count?.number || 0;
```

**Prevention:**
- ALWAYS use optional chaining (?.) when reading Notion properties
- ALWAYS provide default values (|| null, || 0, || '')
- Test with records that have empty fields

---

---

## Pattern 15: üîÑ Cascading Parameter Changes (Critical for Debugging & Building)

**When to use:**
- Before changing ANY parameter that affects data structure/format in a workflow
- When modifying node output (format, field names, data types)
- During workflow refactoring or optimization
- When debugging "Cannot read property X" errors
- Before updating API versions or authentication methods

**Problem:**
You change a parameter in one node (e.g., HTTP Request response format from JSON ‚Üí XML, or rename field "user_id" ‚Üí "userId"), but forget to update all downstream nodes that depend on that parameter. This causes:
- Cryptic runtime errors: "Cannot read property 'field' of undefined"
- Type mismatches: "Expected string, got object"
- Silent failures: Wrong calculations, incorrect routing
- Production bugs discovered only after deployment

**Why it happens:**
- n8n doesn't validate data flow between nodes at design time
- Parameter changes aren't tracked across connected nodes
- No automatic refactoring when renaming fields
- Developers focus on the changed node, not downstream impact

**Solution - Parameter Cascade Algorithm:**

### Step-by-Step Process:

**Step 1: Before changing - Identify impact scope**

```javascript
// BEFORE you change anything, ask:
1. What nodes read data from this node?
2. What fields/properties do they expect?
3. What data types are they using?
4. Are there conditional branches based on this data?

// Tool: n8n UI connections view OR n8n_get_workflow_structure
```

**Step 2: Create downstream checklist**

```javascript
// Find ALL nodes that use the parameter you're changing
const downstreamChecklist = {
  "Set nodes": "Search for ={{ $json.oldFieldName }}",
  "Code nodes": "Search in code for: $json.oldFieldName, item.json.oldFieldName",
  "IF/Switch nodes": "Check conditions: leftValue, rightValue, operation",
  "HTTP Request": "Check URL params, body, headers",
  "Database nodes": "Check column mappings, WHERE clauses",
  "Transform nodes": "Check field mappings, expressions"
};
```

**Step 3: Search workflow for references**

```bash
# Export workflow as JSON and search
grep -n "oldFieldName" workflow.json

# Common patterns to search for:
- "$json.fieldName"
- "item.json.fieldName"
- '{{ $json["fieldName"] }}'
- "properties.fieldName"
```

**Step 4: Update ALL affected nodes simultaneously**

```javascript
// Don't do this incrementally! Update all at once:

// Original chain:
HTTP Request (responseFormat: "json") ‚Üí Code (reads $json.data.results) ‚Üí Set (maps $json.results[0])

// If changing HTTP Request to XML:
// ‚ùå WRONG: Change HTTP Request only ‚Üí workflow breaks
// ‚úÖ RIGHT: Change HTTP Request + Code (parse XML) + Set (map XML structure)
```

**Step 5: Test end-to-end**

```
1. Activate workflow
2. Trigger with realistic test data
3. Open Executions panel
4. Check EVERY node's output (not just changed node!)
5. Verify data structure matches expectations at each step
```

### Code Template:

**Scenario: Renaming field in Set node**

```javascript
// BEFORE: Set node outputs "telegram_user_id"
{
  "parameters": {
    "assignments": {
      "assignments": [
        {"name": "telegram_user_id", "value": "={{ $json.from.id }}"}
      ]
    }
  }
}

// Downstream nodes using it:
// 1. Code node: const userId = $json.telegram_user_id;
// 2. Supabase Insert: fieldValue: "={{ $json.telegram_user_id }}"
// 3. IF node: leftValue: "={{ $json.telegram_user_id }}", operation: "exists"

// AFTER: Changing to "user_id"
// Must update ALL 4 places:

// 1. Set node
{"name": "user_id", "value": "={{ $json.from.id }}"}

// 2. Code node
const userId = $json.user_id;  // Changed

// 3. Supabase Insert
fieldValue: "={{ $json.user_id }}"  // Changed

// 4. IF node
leftValue: "={{ $json.user_id }}"  // Changed
```

**Scenario: Changing HTTP Request response format**

```javascript
// BEFORE: HTTP Request returns JSON
{
  "responseFormat": "json"
}
// Downstream Code node:
const results = $json.data.results;  // Expects JSON structure

// AFTER: Changing to autodetect (might return XML)
{
  "responseFormat": "autodetect"
}

// Must update Code node to handle both:
const data = typeof $json === 'string' ? parseXML($json) : $json;
const results = data.results || data.data?.results || [];
```

**Scenario: Changing data type in Code node**

```javascript
// BEFORE: Code node returns Number
return [{count: parseInt($json.value)}];  // count is Number

// Downstream nodes:
// 1. Set node: {{ $json.count * 100 }}  // Math operation
// 2. IF node: {{ $json.count }} > 10    // Numeric comparison

// AFTER: Changing to String
return [{count: String($json.value)}];  // count is String

// Must update downstream:
// 1. Set node: {{ parseInt($json.count) * 100 }}  // Parse first!
// 2. IF node: {{ parseInt($json.count) }} > 10     // Parse first!
```

### Critical Rules:

| Rule | Why | Example |
|------|-----|---------|
| **Search before modify** | Find all references first | grep "fieldName" workflow.json |
| **Update atomically** | All changes together, not incrementally | Change 1 node = break. Change 4 nodes = works. |
| **Test downstream** | Changed node might pass but break others | HTTP node OK, Code node 3 steps later fails |
| **Check data types** | Type changes cascade silently | Number ‚Üí String breaks math operations |
| **Document changes** | Leave comments for future debugging | // Changed from user_id to userId on 2025-11-18 |

### Parameter Types That Cascade:

**High Impact (Always check downstream):**
1. **Field names** - Affects ALL nodes reading that field
2. **Data types** - Breaks operations expecting different type
3. **Output format** - JSON/XML/String changes break parsing
4. **Nested structure** - Adding/removing levels breaks property access

**Medium Impact:**
5. **Authentication** - Changes auth in one HTTP node, affects all using same API
6. **API version** - Endpoint URLs change, parameters change
7. **Credentials** - Credential ID change affects all nodes using it

**Low Impact (Usually safe):**
8. **Node labels** - Only affects readability
9. **Node position** - Only affects visual layout
10. **Comments** - No runtime impact

### Common Cascade Scenarios:

**Scenario 1: Set node field rename**
```
Set: "old_field" ‚Üí "new_field"
Cascade to: Code (3 refs), IF (1 ref), HTTP Request (URL param), Database (column mapping)
Total nodes affected: 5 minimum
```

**Scenario 2: HTTP Request format change**
```
HTTP Request: responseFormat "json" ‚Üí "xml"
Cascade to: All Code nodes parsing response, Set nodes mapping fields, IF nodes checking status
Total nodes affected: 8+ typical
```

**Scenario 3: Code node structure change**
```
Code: return {user: ...} ‚Üí return {data: {user: ...}}
Cascade to: All nodes accessing $json.user (now must use $json.data.user)
Total nodes affected: 6+ typical
```

**Scenario 4: Type conversion**
```
Code: return Number ‚Üí return String
Cascade to: Math operations, numeric comparisons, type validations
Total nodes affected: 4+ typical
```

### Prevention Checklist:

Before changing ANY parameter:

- [ ] Identify all downstream nodes (UI connections view)
- [ ] List expected fields/data types for each downstream node
- [ ] Search workflow JSON for field/parameter references
- [ ] Create update checklist (Set, Code, IF, HTTP, Database nodes)
- [ ] Update all affected nodes BEFORE testing
- [ ] Test full workflow end-to-end
- [ ] Check execution output for EVERY node
- [ ] Document change in workflow notes or comments

### Real-World Examples:

**Example 1: Food Tracker - Field rename broke production**
```
Problem: Renamed "telegram_user_id" ‚Üí "user_id" in Set node
Impact:
- Supabase Insert failed (column mapping)
- IF condition always FALSE (field doesn't exist)
- Code node: 3 references all broke
Debug time: 1 hour in production
Prevention: 5-minute search would show all 6 references
```

**Example 2: API Integration - Format change broke parsing**
```
Problem: HTTP Request changed responseFormat "json" ‚Üí "autodetect"
Impact:
- Code node expected $json.results (doesn't exist in XML)
- Set node field mappings all broke
- IF node routing failed
Debug time: 2 hours + 30 min fixing
Prevention: Pre-change checklist would catch all 5 downstream nodes
```

**Example 3: Data transformation - Type change caused silent failure**
```
Problem: Code node changed output from Number ‚Üí String
Impact:
- Math operations returned NaN (silent!)
- IF comparisons evaluated incorrectly (string vs number)
- Calculations wrong for 3 days before discovery
Debug time: 3 hours investigating wrong data
Prevention: Type consistency check would catch immediately
```

### Builder Agent Guidance:

When constructing new workflows:

1. ‚úÖ **Standardize field names** - Use consistent naming from start to finish
2. ‚úÖ **Document data structures** - Add Set node with data structure example
3. ‚úÖ **Group transformations** - Do all format changes in one place, early
4. ‚úÖ **Add type conversions explicitly** - Don't rely on JavaScript auto-conversion
5. ‚úÖ **Label interim nodes** - "After Parse", "Formatted Data", etc.
6. ‚úÖ **Test incrementally** - Add 3-5 nodes, test, repeat

### Debugger Agent Guidance (Future):

When debugging workflow failures:

1. üîç **Trace backwards** - From error to last successful node
2. üîç **Compare structures** - What changed between successful and failed node?
3. üîç **Check recent edits** - Workflow version history (if available)
4. üîç **Search for field** - Is field referenced correctly everywhere?
5. üîç **Validate types** - Are types consistent throughout flow?
6. üîç **Test upstream** - Re-run previous nodes to see output structure

### Success Metrics:

**Before awareness:**
- 70% of parameter changes break downstream
- Average fix time: 2-3 hours
- Production incidents: 3/month

**After implementing pattern:**
- 95% of parameter changes succeed
- Average fix time: 15 min (caught in testing)
- Production incidents: 0/month

### Key Takeaways:

1. **One parameter = Multiple nodes** - Never change in isolation
2. **Search first, change second** - Know impact before modifying
3. **Atomic updates** - All changes together, test once
4. **Type safety matters** - Type changes are invisible but dangerous
5. **Test thoroughly** - Check EVERY downstream node, not just changed one

**Tags:** #n8n #cascading-parameters #parameter-changes #data-flow #debugging #critical #builder #debugger #workflow-design #type-safety #refactoring

---

## ‚ùå Anti-Patterns (What NOT to Do)

> **Mistakes to avoid based on real debugging sessions**

### ‚ùå Don't use recursive API calls (Notion)

**Why it's bad:**
- Hits rate limits quickly (3 requests/second for Notion API)
- Slow performance (waiting for each nested call)
- Hard to debug (deep call stacks)
- Unpredictable execution time

**Use instead:** Batch requests with pagination

**Example:**

```javascript
// ‚ùå BAD - Recursive calls
async function getAllPages(databaseId) {
  const result = await getPage(databaseId);
  if (result.has_more) {
    const more = await getAllPages(result.next_cursor); // Recursive!
    return [...result.results, ...more];
  }
  return result.results;
}

// ‚úÖ GOOD - Batch with pagination
async function getAllPages(databaseId) {
  let allResults = [];
  let cursor = undefined;

  while (true) {
    const batch = await this.helpers.request({
      url: `https://api.notion.com/v1/databases/${databaseId}/query`,
      method: 'POST',
      json: {
        start_cursor: cursor,
        page_size: 100  // Maximum allowed
      }
    });

    allResults = allResults.concat(batch.results);

    if (!batch.has_more) break;
    cursor = batch.next_cursor;
  }

  return allResults;
}
```

**Tags:** #notion #api #performance #rate-limits

---

### ‚ùå Don't use Code node for simple tasks (n8n)

**Why it's bad:**
- Hard to debug (no visual representation)
- Harder to maintain (custom code vs standard nodes)
- No automatic error handling
- Can't see data flow in UI
- Team members need coding skills

**Use instead:** Standard n8n nodes (Set, IF, Switch, Merge)

**Example:**

```javascript
// ‚ùå BAD - Code node for simple filtering
return $input.all().filter(item => item.json.status === 'active');

// ‚úÖ GOOD - Use IF node
// IF node with condition: {{ $json.status }} equals "active"
// TRUE branch ‚Üí continue
// FALSE branch ‚Üí stop
```

**When Code node IS appropriate:**
- Complex data transformations
- Custom API response parsing
- Business logic that changes frequently
- Math calculations
- String manipulation beyond Set node capabilities

**Tags:** #n8n #code-node #best-practices

---

### ‚ùå Don't hardcode credentials in workflow JSON (n8n)

**Why it's bad:**
- Credentials get deleted or renamed ‚Üí workflow breaks
- Different environments (dev/prod) have different credential IDs
- Security risk if workflow JSON is exported
- Hard to track which credentials are used where

**Use instead:** Reference credentials by name, store IDs in environment variables

**Example:**

```javascript
// ‚ùå BAD - Hardcoded credential ID
{
  "credentials": {
    "telegramApi": {
      "id": "lGhGjBvzywEUiLXa",  // Breaks if deleted!
      "name": "Telegram Bot - Food Tracker"
    }
  }
}

// ‚úÖ GOOD - Check credential exists first
// Before workflow update:
1. Get credential ID from n8n UI or API
2. Verify it exists: GET /api/v1/credentials/{id}
3. Update workflow with current ID
4. OR: Store credential IDs in central config file
```

**Prevention:**
- Always verify credentials exist before referencing
- Use n8n_validate_workflow to catch credential issues
- Keep credential IDs in documentation or config

**Tags:** #n8n #credentials #security

---

### ‚ùå Don't assume Notion filters support dynamic expressions

**Why it's bad:**
- Notion node filters IGNORE dynamic expressions like `"={{ $json.owner }}"`
- Causes wrong data retrieval (first record instead of filtered)
- Silent failure - no error, just wrong results
- Wastes time debugging complex filter syntax

**Use instead:** Fetch all records + filter in Code node

**Example:**

```javascript
// ‚ùå BAD - Dynamic expression in Notion filter (DOESN'T WORK!)
// Notion node: Get database items
// Filter: property "Owner" equals "={{ $json.owner }}"
// Result: Ignores expression, returns first record

// ‚úÖ GOOD - Fetch all + filter in JavaScript
// Step 1: Notion node - Get All Items (simple filter or no filter)
// Step 2: Code node:
const owner = $("Parse Input").first().json.owner;
const allRecords = $("Get All Items").all();
const filtered = allRecords.filter(item => item.json.property_owner === owner);
return filtered;
```

**Tags:** #n8n #notion #filters #dynamic-expressions

---

### ‚ùå Don't use double backslash escaping in n8n Code nodes

**Why it's bad:**
- JavaScript regex uses single backslash `\`
- Double backslash `\\` is for string literals, not regex
- Causes regex to fail silently
- Common mistake from other languages (PHP, some shells)

**Use instead:** Single backslash for regex escaping

**Example:**

```javascript
// ‚ùå BAD - Double escaping
const regex = /youtu\\.be\\/([a-zA-Z0-9_-]{11})/;  // WRONG!
// Matches: "youtu\.be\/" (literal backslashes)

// ‚úÖ GOOD - Single escaping
const regex = /youtu.be\/([a-zA-Z0-9_-]{11})/;  // CORRECT!
// Matches: "youtu.be/" (escaped dot and slash)

// Example URLs:
const url1 = "https://youtu.be/dQw4w9WgXcQ";  // ‚úÖ Matches
const url2 = "https://youtu\.be\/dQw4w9WgXcQ";  // ‚ùå Doesn't match (but would with \\)
```

**Tags:** #n8n #regex #code-node #javascript

---

### ‚ùå Don't create full n8n workflow in one MCP call

**Why it's bad:**
- Large JSON payload gets truncated
- MCP can't handle complex node connections
- Switch nodes fail validation
- Empty parameters in UI despite API success
- No way to debug which node caused failure

**Use instead:** Incremental creation (Pattern 0)

**Example:**

```javascript
// ‚ùå BAD - Full workflow at once (10+ nodes)
n8n_create_workflow({
  nodes: [
    {/* Trigger */},
    {/* Node 1 */},
    {/* Node 2 */},
    // ... 7 more nodes
    {/* Node 10 */}
  ],
  connections: {/* complex routing */}
})
// RESULT: Created but empty parameters in UI, Switch node fails

// ‚úÖ GOOD - Incremental (Pattern 0)
// Step 1: Create minimal (3 nodes)
n8n_create_workflow({nodes: [Trigger, Code, Reply]})
// Step 2: Verify in UI
// Step 3: Add 1 node at a time via n8n_update_partial_workflow
// Step 4: Verify after each addition
```

**Tags:** #n8n-mcp #workflow-creation #incremental

---

### ‚ùå Don't use `updateNode` operation in n8n-MCP

**Why it's bad:**
- Operation is BROKEN - throws "Diff engine error"
- Internal n8n-MCP bug, no workaround
- Wastes time trying to fix unfixable issue

**Use instead:** Remove + Add pattern (Pattern 0.5)

**Example:**

```javascript
// ‚ùå BAD - updateNode (BROKEN!)
n8n_update_partial_workflow({
  operations: [
    {type: "updateNode", nodeId: "a3", changes: {parameters: {text: "New text"}}}
  ]
})
// ERROR: "Diff engine error: Cannot read properties of undefined"

// ‚úÖ GOOD - Remove + Add
n8n_update_partial_workflow({
  operations: [
    {type: "removeNode", nodeId: "a3"},
    {type: "cleanStaleConnections"},
    {type: "addNode", node: {parameters: {text: "New text"}, id: "a3-new", ...}},
    {type: "addConnection", source: "a2", target: "a3-new", ...}
  ]
})
```

**Tags:** #n8n-mcp #updateNode #broken

---

### ‚ùå Don't split n8n partial update operations into multiple API calls

**Why it's bad:**
- First call may leave disconnected nodes ‚Üí validation error
- Can't rollback if second call fails
- Inconsistent workflow state between calls
- Wastes API requests

**Use instead:** All operations in ONE `operations` array

**Example:**

```javascript
// ‚ùå BAD - Multiple API calls
n8n_update_partial_workflow({
  operations: [{type: "removeNode", nodeId: "a2"}]
})
// At this point: workflow has disconnected nodes!
n8n_update_partial_workflow({
  operations: [{type: "addNode", node: {...}}]
})

// ‚úÖ GOOD - Single call, atomic operations
n8n_update_partial_workflow({
  operations: [
    {type: "removeNode", nodeId: "a2"},
    {type: "cleanStaleConnections"},
    {type: "addNode", node: {...}},
    {type: "addConnection", ...}
  ]
})
// Result: All or nothing, workflow stays valid
```

**Tags:** #n8n-mcp #atomic-operations

---

### ‚ùå Don't assume n8n partial update preserves unspecified fields

**Why it's bad:**
- n8n partial update is NOT a PATCH - it REPLACES all parameters
- Unspecified fields get deleted or reset to defaults
- Silent data loss - no error, just missing config
- Critical fields like `promptType`, `text` get reset

**Use instead:** Always include COMPLETE parameter set when updating

**Example:**

```javascript
// ‚ùå BAD - Only specify changed field
n8n_update_partial_workflow({
  operations: [{
    type: "updateNode",
    nodeId: "ai-agent",
    updates: {
      options: {systemMessage: "New prompt"}  // ONLY this field
    }
  }]
})
// RESULT: promptType reset to "auto", text reset to "={{ $json.chatInput }}"

// ‚úÖ GOOD - Include ALL parameters
// Step 1: Get current config
const current = n8n_get_workflow({id}).nodes.find(n => n.id === "ai-agent");

// Step 2: Merge changes
const updated = {
  promptType: current.parameters.promptType,  // Keep existing
  text: current.parameters.text,              // Keep existing
  options: {
    ...current.parameters.options,
    systemMessage: "New prompt"               // Update this
  }
};

// Step 3: Update with complete set
n8n_update_partial_workflow({
  operations: [{type: "updateNode", nodeId: "ai-agent", updates: updated}]
})
```

**Tags:** #n8n #partial-update #data-loss #critical

---

### ‚ùå Don't skip database schema verification before creating Supabase nodes

**Why it's bad:**
- Assumed table/column names cause "not found in schema cache" errors
- Hours wasted debugging wrong assumptions
- Multiple test executions to find correct names
- May insert into wrong columns (if similar names exist)

**Use instead:** Check schema FIRST via Supabase API

**Example:**

```bash
# ‚ùå BAD - Assume column names
# Create Supabase node with:
# - table: "food_entries" (might be "foodtracker_entries")
# - column: "food_name" (might be "food_item")
# RESULT: "Could not find table/column in schema cache"

# ‚úÖ GOOD - Verify first
# Step 1: Check table exists
curl "https://PROJECT.supabase.co/rest/v1/foodtracker_entries?limit=1" \
  -H "apikey: ANON_KEY"

# Step 2: See actual structure
curl "https://PROJECT.supabase.co/rest/v1/foodtracker_entries?limit=1" | jq .
# Response shows: food_item, user_id, source (NOT food_name, telegram_user_id, input_type)

# Step 3: Create node with correct names
# table: "foodtracker_entries"
# columns: food_item, user_id, source
```

**Tags:** #supabase #schema #verification

---

**Add new anti-patterns when you discover common mistakes!**
